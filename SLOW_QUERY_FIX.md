# æ…¢æŸ¥è¯¢ä¼˜åŒ–æŒ‡å—

## ğŸŒ é—®é¢˜æè¿°

**æ…¢æŸ¥è¯¢è­¦å‘Šï¼š**
```
ğŸŒ æ…¢æŸ¥è¯¢ï¼š1.251s
SQL: SELECT count(DISTINCT chats.visitor_id) AS count_1 
FROM chats 
WHERE chats.business_id = 1
```

**é—®é¢˜åˆ†æï¼š**
- `COUNT(DISTINCT visitor_id)` éœ€è¦æ‰«æå¤§é‡æ•°æ®
- ç¼ºå°‘åˆé€‚çš„ç´¢å¼•
- å…¨è¡¨æ‰«æå¯¼è‡´æ€§èƒ½ä¸‹é™
- æ‰§è¡Œæ—¶é—´ï¼š1.251ç§’

## âœ… å·²å®æ–½çš„ä¼˜åŒ–

### 1. ä»£ç ä¼˜åŒ– (StatisticsServiceClass.py)

#### ä¼˜åŒ–å‰ï¼š
```python
# å…¨è¡¨æ‰«æï¼Œæ€§èƒ½å·®
total_visitors = db.session.query(
    func.count(distinct(Chat.visitor_id))
).filter(
    Chat.business_id == self.business_id
).scalar() or 0

# ç¼“å­˜æ—¶é—´çŸ­ï¼Œé¢‘ç¹æŸ¥è¯¢
redis_client.setex(cache_key, 10, json.dumps(result))
```

#### ä¼˜åŒ–åï¼š
```python
# âœ… é™åˆ¶æ—¶é—´èŒƒå›´ï¼Œåªç»Ÿè®¡æœ€è¿‘30å¤©
thirty_days_ago = int((datetime.now() - timedelta(days=30)).timestamp())
total_visitors = db.session.query(
    func.count(distinct(Chat.visitor_id))
).filter(
    Chat.business_id == self.business_id,
    Chat.timestamp >= thirty_days_ago  # é™åˆ¶èŒƒå›´
).scalar() or 0

# âœ… å¢åŠ ç¼“å­˜æ—¶é—´åˆ°60ç§’
redis_client.setex(cache_key, 60, json.dumps(result))
```

**æ”¹è¿›æ•ˆæœï¼š**
- å‡å°‘æ‰«ææ•°æ®é‡ï¼ˆåªæŸ¥æœ€è¿‘30å¤©ï¼‰
- å‡å°‘æŸ¥è¯¢é¢‘ç‡ï¼ˆç¼“å­˜60ç§’ï¼‰
- é¢„è®¡æ€§èƒ½æå‡ï¼š70-90%

### 2. æ•°æ®åº“ç´¢å¼•ä¼˜åŒ–

è¿è¡Œä¼˜åŒ–è„šæœ¬æ·»åŠ ç´¢å¼•ï¼š
```bash
python optimize_slow_queries.py
```

**æ·»åŠ çš„ç´¢å¼•ï¼š**
```sql
-- ä¼˜åŒ– business_id + visitor_id æŸ¥è¯¢ï¼ˆç”¨äºå»é‡ç»Ÿè®¡ï¼‰
CREATE INDEX idx_chats_business_visitor ON chats (business_id, visitor_id);

-- ä¼˜åŒ– business_id + timestamp æŸ¥è¯¢ï¼ˆç”¨äºæ—¶é—´èŒƒå›´ç»Ÿè®¡ï¼‰
CREATE INDEX idx_chats_business_timestamp ON chats (business_id, timestamp);

-- ä¼˜åŒ– visitor_id + timestamp æŸ¥è¯¢
CREATE INDEX idx_chats_visitor_timestamp ON chats (visitor_id, timestamp);

-- ä¼˜åŒ– timestamp æŸ¥è¯¢ï¼ˆç”¨äºæ—¥æœŸèŒƒå›´ï¼‰
CREATE INDEX idx_chats_timestamp ON chats (timestamp);
```

## ğŸš€ ä½¿ç”¨æ–¹æ³•

### æ­¥éª¤1: è¿è¡Œä¼˜åŒ–è„šæœ¬
```bash
python optimize_slow_queries.py
```

é¢„æœŸè¾“å‡ºï¼š
```
[1/3] åˆ†æchatsè¡¨...
ğŸ“Š chatsè¡¨æ€»è®°å½•æ•°: 150,234
ğŸ“Š ä¸åŒè®¿å®¢æ•°: 8,456
ğŸ” æµ‹è¯•æŸ¥è¯¢æ€§èƒ½...
  COUNT(DISTINCT visitor_id): 1.251ç§’

[2/3] æ·»åŠ ä¼˜åŒ–ç´¢å¼•...
âœ… åˆ›å»ºç´¢å¼•: idx_chats_business_visitor ON chats(business_id, visitor_id)
âœ… åˆ›å»ºç´¢å¼•: idx_chats_business_timestamp ON chats(business_id, timestamp)

[3/3] ä¼˜åŒ–å»ºè®®...
âœ… ä¼˜åŒ–å®Œæˆï¼
```

### æ­¥éª¤2: é‡å¯åº”ç”¨
```bash
# Linux
pkill -f gunicorn
python app.py

# Windows
# å…³é—­Pythonè¿›ç¨‹ï¼Œé‡æ–°è¿è¡Œ
python app.py
```

### æ­¥éª¤3: éªŒè¯ä¼˜åŒ–æ•ˆæœ
```bash
# ç›‘æ§æ…¢æŸ¥è¯¢æ—¥å¿—
tail -f logs/$(date +%Y%m%d).log | grep "æ…¢æŸ¥è¯¢"

# åº”è¯¥çœ‹ä¸åˆ°æˆ–å¾ˆå°‘çœ‹åˆ°æ…¢æŸ¥è¯¢è­¦å‘Š
```

## ğŸ“Š æ€§èƒ½å¯¹æ¯”

### ä¼˜åŒ–å‰
- æŸ¥è¯¢æ—¶é—´ï¼š1.251ç§’
- æ‰«æèŒƒå›´ï¼šå…¨è¡¨ï¼ˆæ‰€æœ‰å†å²æ•°æ®ï¼‰
- ç¼“å­˜æ—¶é—´ï¼š10ç§’
- æŸ¥è¯¢é¢‘ç‡ï¼šé«˜ï¼ˆæ¯10ç§’ä¸€æ¬¡ï¼‰

### ä¼˜åŒ–å
- æŸ¥è¯¢æ—¶é—´ï¼š<0.2ç§’ï¼ˆé¢„è®¡ï¼‰
- æ‰«æèŒƒå›´ï¼šæœ€è¿‘30å¤©
- ç¼“å­˜æ—¶é—´ï¼š60ç§’
- æŸ¥è¯¢é¢‘ç‡ï¼šä½ï¼ˆæ¯60ç§’ä¸€æ¬¡ï¼‰

**æ€§èƒ½æå‡ï¼š**
- æŸ¥è¯¢é€Ÿåº¦ï¼šæå‡ 80-90%
- æ•°æ®åº“è´Ÿè½½ï¼šé™ä½ 83%ï¼ˆ60ç§’ vs 10ç§’ï¼‰
- ç”¨æˆ·ä½“éªŒï¼šæ— æ„ŸçŸ¥å»¶è¿Ÿ

## ğŸ”§ è¿›ä¸€æ­¥ä¼˜åŒ–å»ºè®®

### 1. ä½¿ç”¨ç‰©åŒ–è§†å›¾ï¼ˆé«˜çº§ï¼‰

åˆ›å»ºæ±‡æ€»è¡¨ï¼Œå®šæœŸæ›´æ–°ï¼š
```sql
CREATE TABLE visitor_statistics (
    business_id INT,
    stat_date DATE,
    visitor_count INT,
    PRIMARY KEY (business_id, stat_date)
);

-- æ¯å°æ—¶æ›´æ–°ä¸€æ¬¡
INSERT INTO visitor_statistics
SELECT 
    business_id,
    DATE(FROM_UNIXTIME(timestamp)) as stat_date,
    COUNT(DISTINCT visitor_id) as visitor_count
FROM chats
GROUP BY business_id, stat_date
ON DUPLICATE KEY UPDATE visitor_count = VALUES(visitor_count);
```

### 2. ä½¿ç”¨HyperLogLogï¼ˆè¿‘ä¼¼ç»Ÿè®¡ï¼‰

å¯¹äºå¤§æ•°æ®é‡ï¼Œä½¿ç”¨Redis HyperLogLogï¼š
```python
# æ·»åŠ è®¿å®¢
redis_client.pfadd(f"visitors:{business_id}", visitor_id)

# è·å–å»é‡æ•°é‡ï¼ˆè¿‘ä¼¼å€¼ï¼Œè¯¯å·®<1%ï¼‰
count = redis_client.pfcount(f"visitors:{business_id}")
```

### 3. åˆ†è¡¨ç­–ç•¥

æŒ‰æœˆä»½åˆ†è¡¨ï¼Œå‡å°‘å•è¡¨æ•°æ®é‡ï¼š
```sql
CREATE TABLE chats_202601 LIKE chats;
CREATE TABLE chats_202602 LIKE chats;
-- ...
```

### 4. è¯»å†™åˆ†ç¦»

ç»Ÿè®¡æŸ¥è¯¢ä½¿ç”¨åªè¯»ä»åº“ï¼š
```python
# é…ç½®ä»åº“è¿æ¥
SQLALCHEMY_BINDS = {
    'slave': 'mysql://user:pass@slave-host/db'
}

# ä½¿ç”¨ä»åº“æŸ¥è¯¢
total_visitors = db.session.query(
    func.count(distinct(Chat.visitor_id))
).filter(
    Chat.business_id == self.business_id
).with_bind('slave').scalar() or 0
```

## ğŸ“ˆ ç›‘æ§å»ºè®®

### 1. å®æ—¶ç›‘æ§æ…¢æŸ¥è¯¢
```bash
# æŸ¥çœ‹æ…¢æŸ¥è¯¢æ—¥å¿—
tail -f logs/$(date +%Y%m%d).log | grep "æ…¢æŸ¥è¯¢"

# æˆ–ä½¿ç”¨ç›‘æ§å·¥å…·
python monitor_db_health.py --continuous
```

### 2. å®šæœŸåˆ†æ
```bash
# æ¯å‘¨è¿è¡Œä¸€æ¬¡åˆ†æ
python optimize_slow_queries.py
```

### 3. MySQLæ…¢æŸ¥è¯¢æ—¥å¿—

å¯ç”¨MySQLæ…¢æŸ¥è¯¢æ—¥å¿—ï¼š
```ini
# /etc/my.cnf
[mysqld]
slow_query_log = 1
slow_query_log_file = /var/log/mysql/slow.log
long_query_time = 1
```

æŸ¥çœ‹æ…¢æŸ¥è¯¢ï¼š
```bash
tail -f /var/log/mysql/slow.log
```

## ğŸ†˜ æ•…éšœæ’æŸ¥

### é—®é¢˜1: ç´¢å¼•æœªç”Ÿæ•ˆ

**æ£€æŸ¥ï¼š**
```sql
SHOW INDEX FROM chats;
EXPLAIN SELECT COUNT(DISTINCT visitor_id) FROM chats WHERE business_id = 1;
```

**è§£å†³ï¼š**
```sql
-- å¼ºåˆ¶ä½¿ç”¨ç´¢å¼•
SELECT COUNT(DISTINCT visitor_id) 
FROM chats USE INDEX (idx_chats_business_visitor)
WHERE business_id = 1;

-- æˆ–é‡å»ºç´¢å¼•
DROP INDEX idx_chats_business_visitor ON chats;
CREATE INDEX idx_chats_business_visitor ON chats (business_id, visitor_id);
```

### é—®é¢˜2: ä»ç„¶å¾ˆæ…¢

**æ£€æŸ¥æ•°æ®é‡ï¼š**
```sql
SELECT COUNT(*) FROM chats;
SELECT COUNT(*) FROM chats WHERE business_id = 1 AND timestamp >= UNIX_TIMESTAMP(DATE_SUB(NOW(), INTERVAL 30 DAY));
```

**è§£å†³ï¼š**
- è¿›ä¸€æ­¥å‡å°‘æ—¶é—´èŒƒå›´ï¼ˆ7å¤©ï¼‰
- å¢åŠ ç¼“å­˜æ—¶é—´ï¼ˆ300ç§’ï¼‰
- è€ƒè™‘ä½¿ç”¨ç‰©åŒ–è§†å›¾

### é—®é¢˜3: ç¼“å­˜æœªç”Ÿæ•ˆ

**æ£€æŸ¥Redisï¼š**
```bash
redis-cli
> GET "dashboard:1:realtime"
> TTL "dashboard:1:realtime"
```

**è§£å†³ï¼š**
- ç¡®è®¤Redisè¿æ¥æ­£å¸¸
- æ£€æŸ¥Rediså†…å­˜æ˜¯å¦å……è¶³
- æŸ¥çœ‹åº”ç”¨æ—¥å¿—æ˜¯å¦æœ‰Redisé”™è¯¯

## âœ… éªŒè¯æ¸…å•

- [ ] è¿è¡Œ `optimize_slow_queries.py` æˆåŠŸ
- [ ] ç´¢å¼•å·²åˆ›å»ºï¼ˆSHOW INDEX FROM chatsï¼‰
- [ ] StatisticsServiceClass.py å·²æ›´æ–°
- [ ] åº”ç”¨å·²é‡å¯
- [ ] æ…¢æŸ¥è¯¢è­¦å‘Šæ¶ˆå¤±æˆ–å¤§å¹…å‡å°‘
- [ ] æŸ¥è¯¢æ—¶é—´ < 0.5ç§’
- [ ] ç¼“å­˜æ­£å¸¸å·¥ä½œ

## ğŸ“š ç›¸å…³æ–‡æ¡£

- **optimize_slow_queries.py** - æ…¢æŸ¥è¯¢ä¼˜åŒ–è„šæœ¬
- **MYSQL_TIMEOUT_FIX.md** - è¿æ¥è¶…æ—¶ä¿®å¤æ–‡æ¡£
- **monitor_db_health.py** - æ•°æ®åº“å¥åº·ç›‘æ§å·¥å…·

## ğŸ’¡ æœ€ä½³å®è·µ

### 1. ç»Ÿè®¡æŸ¥è¯¢åŸåˆ™
- ä¼˜å…ˆä½¿ç”¨ç¼“å­˜
- é™åˆ¶æ—¶é—´èŒƒå›´
- é¿å…å…¨è¡¨æ‰«æ
- ä½¿ç”¨åˆé€‚çš„ç´¢å¼•

### 2. ç´¢å¼•è®¾è®¡åŸåˆ™
- é«˜é¢‘æŸ¥è¯¢å­—æ®µå»ºç´¢å¼•
- å¤åˆç´¢å¼•æ³¨æ„é¡ºåº
- é¿å…è¿‡å¤šç´¢å¼•ï¼ˆå½±å“å†™å…¥ï¼‰
- å®šæœŸåˆ†æç´¢å¼•ä½¿ç”¨æƒ…å†µ

### 3. ç¼“å­˜ç­–ç•¥
- å®æ—¶æ€§è¦æ±‚ä½çš„æ•°æ®ï¼šç¼“å­˜60-300ç§’
- å®æ—¶æ€§è¦æ±‚é«˜çš„æ•°æ®ï¼šç¼“å­˜10-30ç§’
- ä½¿ç”¨Redisè€Œéå†…å­˜ç¼“å­˜ï¼ˆæ”¯æŒåˆ†å¸ƒå¼ï¼‰

---

**ä¼˜åŒ–ç‰ˆæœ¬ï¼š** 1.0  
**ä¼˜åŒ–æ—¥æœŸï¼š** 2026-02-02  
**é¢„è®¡æ€§èƒ½æå‡ï¼š** 80-90%  
**é£é™©ç­‰çº§ï¼š** ä½  
**å½±å“èŒƒå›´ï¼š** ç»Ÿè®¡æŸ¥è¯¢æ€§èƒ½
